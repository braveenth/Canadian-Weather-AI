{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyP8NGUuywsuTzFEBAyLjrIF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/braveenth/Canadian-Weather-AI/blob/main/Canadian_Weather_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Canadian Weather AI\n",
        "By: Braveenth Rasanayagam\n",
        "\n",
        "Multi-modal\n",
        "- Vision\n",
        "- Text to Voice\n",
        "\n",
        "Cloud Run Jobs"
      ],
      "metadata": {
        "id": "umi3NzPEIRQ2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 774
        },
        "id": "O2Z0y6IIqPsr",
        "outputId": "277a7dc1-52db-4aea-b5f1-129cbe5f63f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://weather.gc.ca/data/jet_stream/tempmapwx_e.gif\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  268k  100  268k    0     0  1010k      0 --:--:-- --:--:-- --:--:-- 1011k\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://weather.gc.ca/data/jet_stream/tempmapwx_e.gif\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "image_url = \"https://weather.gc.ca/data/jet_stream/tempmapwx_e.gif\"\n",
        "print(image_url)\n",
        "!curl -o case_image.png {image_url}\n",
        "\n",
        "from IPython.display import Image\n",
        "Image(\"/content/jet_stream.png\")\n",
        "Image(url=image_url)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "\n",
        "try:\n",
        "    # Attempt to import the google.colab module to see if the program is running in Colab.\n",
        "    from google.colab import userdata\n",
        "    print(\"Running on Google Colab\")\n",
        "    !pip install openai\n",
        "    !pip install pydub\n",
        "    !pip install anthropic\n",
        "    !pip install -U -q google-generativeai\n",
        "    !pip install langchain_groq\n",
        "    !pip install groq\n",
        "    from openai import OpenAI\n",
        "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "    ANTHRONPIC_API_KEY = userdata.get('ANTHROPIC_API_KEY')\n",
        "    GOOGLE_API_KEY = userdata.get('AI_STUDIO_KEY')\n",
        "    HF_API_KEY = userdata.get('HF_ACCESS_KEY')\n",
        "    GROQ_API_KEY = userdata.get('GROQ_API_KEY')\n",
        "    !mkdir -p /content/text\n",
        "    !mkdir -p /content/voice\n",
        "    !mkdir -p /content/assets\n",
        "    !mkdir -p /content/metadata\n",
        "    !mkdir -p /content/weatherperson\n",
        "    !curl -o \"/content/assets/WeatherNetwork.mp3\" \"https://storage.googleapis.com/can-weather-ai/assets/WeatherNetwork.mp3\"\n",
        "\n",
        "except ImportError:\n",
        "    # The ImportError exception will be raised if the google.colab module is not found,\n",
        "    # indicating that the program is not running inside Google Colab.\n",
        "    print(\"Running outside of Google Colab\")\n",
        "    from openai import OpenAI\n",
        "    OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')\n",
        "    ANTHRONPIC_API_KEY = os.environ.get('ANTHROPIC_API_KEY')\n",
        "    GOOGLE_API_KEY = os.environ.get('GOOGLE_AI_STUDIO_KEY')\n",
        "    HF_API_KEY = os.environ.get('HF_ACCESS_KEY')\n",
        "    GROQ_API_KEY = os.environ.get('GROQ_API_KEY')\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DWsynJMzX29",
        "outputId": "19e365e9-ea38-4a7d-9dab-019d1a106f7f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on Google Colab\n",
            "Collecting openai\n",
            "  Downloading openai-1.29.0-py3-none-any.whl (320 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.3/320.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.29.0\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n",
            "Collecting anthropic\n",
            "  Downloading anthropic-0.25.8-py3-none-any.whl (870 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m870.8/870.8 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from anthropic) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (0.19.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from anthropic) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->anthropic) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->anthropic) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.18.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.0->anthropic) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (4.66.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (6.0.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (24.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.0.7)\n",
            "Installing collected packages: anthropic\n",
            "Successfully installed anthropic-0.25.8\n",
            "Collecting langchain_groq\n",
            "  Downloading langchain_groq-0.1.3-py3-none-any.whl (11 kB)\n",
            "Collecting groq<1,>=0.4.1 (from langchain_groq)\n",
            "  Downloading groq-0.5.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.45 (from langchain_groq)\n",
            "  Downloading langchain_core-0.1.52-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain_groq) (4.11.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.45->langchain_groq) (6.0.1)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.2.0,>=0.1.45->langchain_groq)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.0 (from langchain-core<0.2.0,>=0.1.45->langchain_groq)\n",
            "  Downloading langsmith-0.1.57-py3-none-any.whl (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.0/121.0 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.45->langchain_groq)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.45->langchain_groq) (8.3.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (0.14.0)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.45->langchain_groq)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.45->langchain_groq)\n",
            "  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.45->langchain_groq) (2.31.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (2.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.45->langchain_groq) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.45->langchain_groq) (2.0.7)\n",
            "Installing collected packages: packaging, orjson, jsonpointer, jsonpatch, langsmith, groq, langchain-core, langchain_groq\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed groq-0.5.0 jsonpatch-1.33 jsonpointer-2.4 langchain-core-0.1.52 langchain_groq-0.1.3 langsmith-0.1.57 orjson-3.10.3 packaging-23.2\n",
            "Requirement already satisfied: groq in /usr/local/lib/python3.10/dist-packages (0.5.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (2.18.2)\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 64.1M  100 64.1M    0     0  40.3M      0  0:00:01  0:00:01 --:--:-- 40.3M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This will be incorporated into the prompt in the future\n",
        "\n",
        "canadianMetric = {}\n",
        "\n",
        "canadianMetric[0] = \"not Canadian\"\n",
        "canadianMetric[1] = \"somewhat Canadian\"\n",
        "canadianMetric[2] = \"slightly Canadian\"\n",
        "canadianMetric[3] = \"moderately Canadian\"\n",
        "canadianMetric[4] = \"very Canadian\"\n",
        "canadianMetric[5] = \"as Canadian as possible\"\n",
        "\n",
        "selectedCanadianMetric = canadianMetric[4]\n",
        "langauge = \"en\"\n",
        "\n",
        "# We are allowing for multiple models to be incorporated\n",
        "modelChoice = {}\n",
        "\n",
        "modelChoice[0] = \"gpt-4-vision-preview\"\n",
        "modelChoice[1] = \"claude-3-opus-20240229\"\n",
        "modelChoice[2] = \"gemini-pro-vision\"\n",
        "modelChoice[3] = \"gemini-1.5-pro-latest\"\n",
        "modelChoice[4] = \"llama3-70b-8192\"\n",
        "modelChoice[5] = \"gpt-4o\"\n",
        "\n",
        "selectedModel = modelChoice[5]"
      ],
      "metadata": {
        "id": "V8VydbPVFggt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "makeLyrics = False\n",
        "musicPrompt = {}\n",
        "musicPrompt[0] = \"Make lyrics for a beautiful melodic song.\"\n",
        "musicPrompt[1] = \"Make lyrics for a alternative rock song, male vocals, powerful.\"\n",
        "musicPrompt[2] = \"Make lyrics for a RnB song, female vocals, 2000s influence.\"\n"
      ],
      "metadata": {
        "id": "ZeF9QG_zlaC0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imagePrompt = \"You are a Canadian weatherperson. Present this jet stream information to an audience. Make it sound very Canadian. It should sound as Canadian as absolutely possible.\"\n",
        "image_url = \"https://weather.gc.ca/data/jet_stream/tempmapwx_e.gif\"\n",
        "\n",
        "if selectedModel[0:5] == \"gpt-4\":\n",
        "  gpt_mode = selectedModel\n",
        "  imagePrompt = \"You are a Canadian weatherperson. Present this jet stream information to an audience. Make it sound very Canadian. It should sound as Canadian as absolutely possible.\"\n",
        "  image_url = \"https://weather.gc.ca/data/jet_stream/tempmapwx_e.gif\"\n",
        "  multimodalModelOrg = \"OpenAI\"\n",
        "\n",
        "  response = client.chat.completions.create(\n",
        "    model=gpt_mode,\n",
        "    messages=[\n",
        "      {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "          {\"type\": \"text\", \"text\": imagePrompt},\n",
        "          {\n",
        "            \"type\": \"image_url\",\n",
        "            \"image_url\": {\n",
        "              \"url\": image_url,\n",
        "            },\n",
        "          },\n",
        "        ],\n",
        "      }\n",
        "    ],\n",
        "    max_tokens=600,\n",
        "    temperature=0.7,\n",
        "    top_p=1,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0\n",
        "  )\n",
        "  weatherScript = response.choices[0].message.content\n",
        "  print(response.choices[0])\n",
        "\n",
        "elif selectedModel == \"claude-3-opus-20240229\":\n",
        "  import anthropic\n",
        "  import base64\n",
        "  import httpx\n",
        "  claude_mode = \"claude-3-opus-20240229\"\n",
        "  multimodalModelOrg = \"Anthropic\"\n",
        "\n",
        "  client = anthropic.Anthropic(\n",
        "      api_key=ANTHRONPIC_API_KEY,\n",
        "  )\n",
        "\n",
        "  image_media_type = \"image/gif\"\n",
        "  image_data = base64.b64encode(httpx.get(image_url).content).decode(\"utf-8\")\n",
        "  imagePrompt += \"Do not put any statements with asterisks surrounding them. Only give the speech, and nothing else. For example, statements similar to the following should be excluded: *clears throat*\"\n",
        "\n",
        "  message = client.messages.create(\n",
        "      model=\"claude-3-opus-20240229\",\n",
        "      max_tokens=1024,\n",
        "      messages=[\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": [\n",
        "                  {\n",
        "                      \"type\": \"image\",\n",
        "                      \"source\": {\n",
        "                          \"type\": \"base64\",\n",
        "                          \"media_type\": image_media_type,\n",
        "                          \"data\": image_data,\n",
        "                      },\n",
        "                  },\n",
        "                  {\n",
        "                      \"type\": \"text\",\n",
        "                      \"text\": imagePrompt\n",
        "                  }\n",
        "              ],\n",
        "          }\n",
        "      ],\n",
        "  )\n",
        "  weatherScript = message.content[0].text\n",
        "  print(weatherScript)\n",
        "\n",
        "\n",
        "elif selectedModel == \"gemini-1.5-pro-latest\":\n",
        "  # from vertexai.generative_models import GenerativeModel, Part, FinishReason\n",
        "  # import vertexai.preview.generative_models as generative_models\n",
        "  # model = genai.GenerativeModel('models/gemini-1.5-pro-latest')\n",
        "  #model = genai.GenerativeModel('models/gemini-1.5-pro-latest')\n",
        "  #imagePrompt = \"You are a Canadian weatherperson. Present this jet stream information to an audience. Make it sound very Canadian. It should sound as Canadian as absolutely possible.\"\n",
        "  imagePrompt = \"You are a Canadian weatherperson. Present this jet stream information to an audience. Make it sound very Canadian. It should sound as Canadian as absolutely possible.\"\n",
        "  image_url = \"https://weather.gc.ca/data/jet_stream/tempmapwx_e.gif\"\n",
        "  multimodalModelOrg = \"Google\"\n",
        "\n",
        "  generation_config = {\n",
        "      \"max_output_tokens\": 8192,\n",
        "      \"temperature\": 1,\n",
        "      \"top_p\": 0.95,\n",
        "  }\n",
        "\n",
        "  safety_settings = {\n",
        "    # generative_models.HarmCategory.HARM_CATEGORY_HATE_SPEECH: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "    # generative_models.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "    # generative_models.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "    # generative_models.HarmCategory.HARM_CATEGORY_HARASSMENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "  }\n",
        "\n",
        "  model = genai.GenerativeModel(model_name=\"gemini-1.5-pro-latest\",\n",
        "                                generation_config=generation_config,\n",
        "                                safety_settings=safety_settings)\n",
        "\n",
        "  # print(.GenerativeModel.ListModels())\n",
        "  response = model.generate_content(\n",
        "      [imagePrompt, image_url],\n",
        "      generation_config=generation_config,\n",
        "      safety_settings=safety_settings,\n",
        "      stream=False,\n",
        "      )\n",
        "\n",
        "  # for response in responses:\n",
        "  #   print(response.text, end=\"\")\n",
        "\n",
        "  weatherScript = response.text\n",
        "  print(weatherScript)\n",
        "\n",
        "elif selectedModel == \"llama3-70b-8192-GPU\":\n",
        "  # from langchain_groq import Groq\n",
        "  import transformers\n",
        "  import torch\n",
        "  from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "  model_id = \"meta-llama/Meta-Llama-3-8B\"\n",
        "  !pip install accelerate\n",
        "\n",
        "  tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B\", token=HF_API_KEY)\n",
        "  model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Meta-Llama-3-8B\", token=HF_API_KEY)\n",
        "\n",
        "elif selectedModel == \"llama3-70b-8192\":\n",
        "  prompt = \"You are a Canadian weatherperson. Present this jet stream information to an audience. Make it sound very Canadian. It should sound as Canadian as absolutely possible. You will only output what the weatherperson would speak.\"\n",
        "\n",
        "  if makeLyrics == True:\n",
        "    prompt = \"You are a Canadian weatherperson. Present this jet stream information to an audience. You will only output lyrics. Make sure you cover the weather information so that listeners are aware of the resulting weather from the jet stream information.\"\n",
        "    prompt += musicPrompt[0]\n",
        "    prompt += \"Use [Verse], [Bridge], and [Chorus] tags for additional control.\"\n",
        "\n",
        "  multimodalModelOrg = \"Meta\"\n",
        "  from groq import Groq\n",
        "\n",
        "  client = Groq(\n",
        "      api_key=GROQ_API_KEY,\n",
        "  )\n",
        "\n",
        "  chat_completion = client.chat.completions.create(\n",
        "      messages=[\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": f\"Image: {image_url}. {prompt}\",\n",
        "          }\n",
        "      ],\n",
        "      model=\"llama3-70b-8192\",\n",
        "  )\n",
        "\n",
        "  client.chat.completions.create\n",
        "\n",
        "  weatherScript = chat_completion.choices[0].message.content\n"
      ],
      "metadata": {
        "id": "1ChT820dxzsj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae4085dc-995d-4547-b951-8a538ba0bc70"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Oh, hey there, Canada! Got a beauty of a jet stream update for ya, so grab your Timmies and let's dive in, eh?\\n\\nAlrighty, folks, up in the north, we've got some chilly temperatures, as you'd expect this time of year. The jet stream is dipping down, bringing some of that cold Arctic air with it. We’re seeing temperatures in the minus 30s up there in the territories. So bundle up if you're heading out, and don’t forget your toque!\\n\\nMoving west, over B.C., we've got a low pressure system hanging around. It's pushing warmer air from the Pacific inland, so parts of the province are seeing temperatures above 10 degrees. Not too shabby, eh? But watch out for some wet and wild weather as that moisture moves in.\\n\\nNow, over the Prairies, it's a mixed bag, folks. The jet stream is pretty active here, with a bit of everything going on. We've got some warmer air trying to sneak in from the south, but those northern winds are keeping things cool. So, if you're out in Alberta, Saskatchewan, or Manitoba, you might need to keep your layers handy.\\n\\nHeading east, towards Ontario and Quebec, we’re seeing some warmer air making its way up from the south, too. Temperatures here are a bit more mild, hanging around the 10 to 15 degree mark. But there's a low pressure system bringing some rain showers, so your umbrella might be your best friend for a bit.\\n\\nFinally, out in the Maritimes, the jet stream is really on the move. We're seeing some warmer temperatures as well, but those lows are bringing in some rain. So, folks in Newfoundland and the rest of the Atlantic provinces, get ready for a bit of a soggy spell.\\n\\nWell, there ya have it, Canada. Keep your chin up, stay warm, and as always, be prepared for whatever Mother Nature throws our way. Stay safe out there, and we'll catch ya later, eh?\", role='assistant', function_call=None, tool_calls=None))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(weatherScript)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4no0kaGL0tAT",
        "outputId": "b30b037d-0c76-4ce4-8e32-4cca9f13d8ee"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Oh, hey there, Canada! Got a beauty of a jet stream update for ya, so grab your Timmies and let's dive in, eh?\n",
            "\n",
            "Alrighty, folks, up in the north, we've got some chilly temperatures, as you'd expect this time of year. The jet stream is dipping down, bringing some of that cold Arctic air with it. We’re seeing temperatures in the minus 30s up there in the territories. So bundle up if you're heading out, and don’t forget your toque!\n",
            "\n",
            "Moving west, over B.C., we've got a low pressure system hanging around. It's pushing warmer air from the Pacific inland, so parts of the province are seeing temperatures above 10 degrees. Not too shabby, eh? But watch out for some wet and wild weather as that moisture moves in.\n",
            "\n",
            "Now, over the Prairies, it's a mixed bag, folks. The jet stream is pretty active here, with a bit of everything going on. We've got some warmer air trying to sneak in from the south, but those northern winds are keeping things cool. So, if you're out in Alberta, Saskatchewan, or Manitoba, you might need to keep your layers handy.\n",
            "\n",
            "Heading east, towards Ontario and Quebec, we’re seeing some warmer air making its way up from the south, too. Temperatures here are a bit more mild, hanging around the 10 to 15 degree mark. But there's a low pressure system bringing some rain showers, so your umbrella might be your best friend for a bit.\n",
            "\n",
            "Finally, out in the Maritimes, the jet stream is really on the move. We're seeing some warmer temperatures as well, but those lows are bringing in some rain. So, folks in Newfoundland and the rest of the Atlantic provinces, get ready for a bit of a soggy spell.\n",
            "\n",
            "Well, there ya have it, Canada. Keep your chin up, stay warm, and as always, be prepared for whatever Mother Nature throws our way. Stay safe out there, and we'll catch ya later, eh?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the weatherScript as a file\n",
        "from datetime import datetime\n",
        "\n",
        "# Adding timezone\n",
        "import pytz\n",
        "timezone = pytz.timezone('America/Toronto')\n",
        "now_in_timezone = datetime.now(timezone)\n",
        "\n",
        "# Format the date\n",
        "date = now_in_timezone.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "#date = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "count = 0\n",
        "\n",
        "while os.path.exists(f\"/content/text/ai-canadian-jetstream-{date}_{count}.txt\"):\n",
        "    count += 1\n",
        "file = open(f\"/content/text/ai-canadian-jetstream-{date}_{count}.txt\", \"w\")\n",
        "file.write(weatherScript)\n",
        "file.close()"
      ],
      "metadata": {
        "id": "4xmiS2I3a3Sp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "try:\n",
        "    # Attempt to import the google.colab module to see if the program is running in Colab.\n",
        "    from google.colab import userdata\n",
        "    print(\"Running on Google Colab\")\n",
        "    audioClient = OpenAI(api_key=userdata.get('OPENAI_API_KEY'))\n",
        "\n",
        "except ImportError:\n",
        "    # The ImportError exception will be raised if the google.colab module is not found,\n",
        "    # indicating that the program is not running inside Google Colab.\n",
        "    import os\n",
        "    print(\"Running outside of Google Colab\")\n",
        "    audioClient = OpenAI(api_key=(os.environ.get('OPENAI_API_KEY')))\n",
        "\n",
        "audioModelOrg = \"OpenAI\"\n",
        "audioModel = \"tts-1\"\n",
        "audioVoice = \"onyx\"\n",
        "\n",
        "audioResponse = audioClient.audio.speech.create(\n",
        "    model=audioModel,\n",
        "    voice=audioVoice,\n",
        "    input=weatherScript,\n",
        ")\n",
        "\n",
        "filename = f\"weatherperson-output-{date}.mp3\""
      ],
      "metadata": {
        "id": "3ZH_07Z71B7C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfb529b5-6cce-48ab-9359-e7aa04f8b10f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on Google Colab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audioResponse.stream_to_file(filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3cSZyLe2GXl",
        "outputId": "02888db0-dc0b-45f8-ad29-6ffdb8158aa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-02f298be9c94>:1: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
            "  audioResponse.stream_to_file(filename)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "\n",
        "# Export the result\n",
        "weatherPersonFileCount = 0\n",
        "while os.path.exists(f\"/content/weatherperson/weatherperson-output-{date}_{weatherPersonFileCount}.wav\"):\n",
        "    weatherPersonFileCount += 1\n",
        "\n",
        "weatherpersonFile = f\"/content/weatherperson/{filename}-{count}\"\n",
        "audioResponse.stream_to_file(f\"/content/weatherperson/weatherperson-output-{date}_{weatherPersonFileCount}.wav\")\n",
        "\n",
        "# Obtain Audio Files\n",
        "audio_bg_music = AudioSegment.from_file(\"/content/assets/WeatherNetwork.mp3\", format=\"mp3\")\n",
        "audio_weatherperson = AudioSegment.from_file(f\"/content/weatherperson/weatherperson-output-{date}_{weatherPersonFileCount}.wav\", format=\"mp3\")\n",
        "\n",
        "# BG Music Segments from https://www.youtube.com/watch?v=6E2uzYAGPQU\n",
        "#####################################################################\n",
        "# 01. Morning Report (1998) Conclusions 0:00. #\n",
        "# 02. Autumn (1999) Flying V.1 1:59 #\n",
        "# 03. Holidays (2000) Xmas Spirit 3:29\n",
        "# 04. Biding My Time 4:59\n",
        "# 05. Winter (2002-'03) Life to the Full 7:12\n",
        "# 06. Spring-Autumn (2003) Healthy Outlook 8:42\n",
        "# 07. Winter (2003-04) Embrace Life 10:43\n",
        "# 08. Primary Theme (2004-05) Lazing on the Slopes 13:16\n",
        "# 09. Theme (2005-06) Windstar 15:17\n",
        "# 10. Theme (2006-10) 17:17\n",
        "# 11. Theme (2010-201?) Song Contest Winner 19:37\n",
        "# 12. Holiday Version of Theme 11 (2011) 21:58\n",
        "# 13. 25th Anniversary (2004-05 Secondary Theme) 25:02\n",
        "\n",
        "segments = [0] * 12\n",
        "segments[0] = [0, 119000, 7]\n",
        "segments[1] = [119000, 209000, 7]\n",
        "segments[2] = [209000, 299000, 7]\n",
        "segments[3] = [299000, 432000, 7]\n",
        "segments[4] = [432000, 522000, 7]\n",
        "segments[5] = [522000, 643000, 7]\n",
        "segments[6] = [643000, 796000, 7]\n",
        "segments[7] = [796000, 917000, 7]\n",
        "segments[8] = [917000, 1037000, 7]\n",
        "segments[9] = [1037000, 1177000, 7]\n",
        "segments[10] = [1177000, 1318000, 11]\n",
        "segments[11] = [1318000, 1502000, 7]\n",
        "\n",
        "# Custom timing adjustments based on listening observations\n",
        "segments[8][0] = segments[8][0] + 8000\n",
        "\n",
        "# Define start and end times in milliseconds\n",
        "# Start at 17:22\n",
        "# End at 17:3\n",
        "start_time = 1042000  # Start at 10 seconds\n",
        "end_time = start_time + 120000\n",
        "\n",
        "# Use a Random number between 0 an 11 to obtain the segment number\n",
        "import random\n",
        "segment_number = random.randint(0, 11)\n",
        "\n",
        "# Using Segments Here\n",
        "start_time = segments[segment_number][0] + 1000\n",
        "end_time = segments[segment_number][1]\n",
        "\n",
        "# Slice the audio segment to the desired part\n",
        "specific_part = audio_bg_music[start_time:end_time]\n",
        "\n",
        "# Lower the volume by 10 dB\n",
        "specific_part_quieter = specific_part - segments[segment_number][2]\n",
        "\n",
        "# TO-DO: if the audio_weatherperson audio length is longer than the specific_part_quieter, then add some padding to the end of the specific_part_quieter\n",
        "lenBackgroundMusicMS = end_time - start_time\n",
        "lenAudioWeatherPersonMS = len(audio_weatherperson)\n",
        "if lenAudioWeatherPersonMS > lenBackgroundMusicMS:\n",
        "    from pydub.generators import Silence\n",
        "    padding_length_ms = lenAudioWeatherPersonMS - lenBackgroundMusicMS + 1000\n",
        "    #padding = Silence().to_audio_segment(duration=padding_length_ms, frame_rate=44100)\n",
        "    padding = AudioSegment.silent(duration=padding_length_ms)\n",
        "    specific_part_quieter = specific_part_quieter.append(padding)\n",
        "\n",
        "# TO_DO: Add audio ducking\n",
        "\n",
        "# Overlay the audio files\n",
        "# Here, overlay_audio will start at 0 milliseconds into base_audio\n",
        "combined = specific_part_quieter.overlay(audio_weatherperson, position=0)\n",
        "\n",
        "# Export the result\n",
        "count = 0\n",
        "while os.path.exists(f\"/content/voice/ai-canadian-jetstream-{date}_{count}.mp3\"):\n",
        "    count += 1\n",
        "combined.export(f\"/content/voice/ai-canadian-jetstream-{date}_{count}.mp3\", format=\"mp3\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSjR8yY93MMI",
        "outputId": "2f1d50bf-44d0-494b-cf83-6637cf4d2567"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-0b25720dc80f>:9: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
            "  audioResponse.stream_to_file(f\"/content/weatherperson/weatherperson-output-{date}_{weatherPersonFileCount}.wav\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_io.BufferedRandom name='/content/voice/ai-canadian-jetstream-2024-05-01_0.mp3'>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Escape the newlines in the weatherScript\n",
        "weatherScriptEscapedString = weatherScript.replace(\"\\n\", \"\\\\n\")\n",
        "print(weatherScriptEscapedString)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "862hBj2xEZT_",
        "outputId": "3838d9c2-c18d-4de3-8ab7-c37876c41055"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Buddy, take a gander at this jet stream map, eh! You'll notice we've got a bit of a wild ride goin' on across the Great White North, ay. A strong high-pressure system is parked over the Prairie provinces, bringin' some nice, warm air from the southwest, and that's gonna give us a real nice stretch of weather, especially in Alberta and Saskatchewan. You folks in Calgary and Edmonton, get ready for a beaut day, with temps soaring into the mid-teens, Celsius, of course! That's practically shorts weather, buddy!\\n\\nNow, on the flip side, we've got a low-pressure system movin' into the Maritimes, and that's gonna bring some wet and windy weather to our friends in Nova Scotia, New Brunswick, and Prince Edward Island. Sorry, buddies, but it looks like the umbrella's gonna be your best friend for the next 24 hours.\\n\\nMeanwhile, out in British Columbia, you're lookin' at some lovely, mild air comin' in off the Pacific, so Vancouver and Victoria, you're in for a treat, eh! Just a beautiful day to get out and enjoy the great outdoors, maybe take a stroll along the seawall or hike the Grouse Grind, if you're feelin' ambitious.\\n\\nAnd finally, across the Territories, it's still a bit chilly, but hey, that's what happens when you're livin' in the Arctic, right? Just remember to bundle up, and don't forget that toque, ay!\\n\\nSo, that's the latest on the jet stream, folks! Stay warm, stay dry, and we'll catch you on the flip side, eh?\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TO-DO: Create JSON that can be imported into BigQuery\n",
        "# Use Colab's Variable Inspector to determine which variables shoudl be captured.\n",
        "\n",
        "metadata_json = f\"\"\"{{\n",
        "  \"timestamp\": \"{date}\",\n",
        "  \"timezone\": \"{timezone}\",\n",
        "  \"weatherScript\": \"{weatherScriptEscapedString}\",\n",
        "  \"weatherScriptPath\": \"/content/text/ai-canadian-jetstream-{date}_{count}.txt\",\n",
        "  \"modelOrganization\": \"{multimodalModelOrg}\",\n",
        "  \"modelName\": \"{selectedModel}\",\n",
        "  \"imagePrompt\": \"{imagePrompt}\",\n",
        "  \"imageUrl\": \"{image_url}\",\n",
        "  \"audioModelOrganization\": \"{audioModelOrg}\",\n",
        "  \"audioModelName\": \"{audioModel}\",\n",
        "  \"audioVoice\": \"{audioVoice}\",\n",
        "  \"speechAudioOutputPath\": \"/content/weatherperson/weatherperson-output-{date}_{weatherPersonFileCount}.wav\",\n",
        "  \"combinedAudioOutputPath\": \"/content/voice/ai-canadian-jetstream-{date}_{count}.mp3\"\n",
        "}}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "p0913eMcWFOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(metadata_json)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhpZYKoAFkhf",
        "outputId": "2e092053-6fcc-413f-b2bd-3522783d4b38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"timestamp\": \"2024-05-01\",\n",
            "  \"timezone\": \"America/Toronto\",\n",
            "  \"weatherScript\": \"\"Buddy, take a gander at this jet stream map, eh! You'll notice we've got a bit of a wild ride goin' on across the Great White North, ay. A strong high-pressure system is parked over the Prairie provinces, bringin' some nice, warm air from the southwest, and that's gonna give us a real nice stretch of weather, especially in Alberta and Saskatchewan. You folks in Calgary and Edmonton, get ready for a beaut day, with temps soaring into the mid-teens, Celsius, of course! That's practically shorts weather, buddy!\\n\\nNow, on the flip side, we've got a low-pressure system movin' into the Maritimes, and that's gonna bring some wet and windy weather to our friends in Nova Scotia, New Brunswick, and Prince Edward Island. Sorry, buddies, but it looks like the umbrella's gonna be your best friend for the next 24 hours.\\n\\nMeanwhile, out in British Columbia, you're lookin' at some lovely, mild air comin' in off the Pacific, so Vancouver and Victoria, you're in for a treat, eh! Just a beautiful day to get out and enjoy the great outdoors, maybe take a stroll along the seawall or hike the Grouse Grind, if you're feelin' ambitious.\\n\\nAnd finally, across the Territories, it's still a bit chilly, but hey, that's what happens when you're livin' in the Arctic, right? Just remember to bundle up, and don't forget that toque, ay!\\n\\nSo, that's the latest on the jet stream, folks! Stay warm, stay dry, and we'll catch you on the flip side, eh?\"\",\n",
            "  \"weatherScriptPath\": \"/content/text/ai-canadian-jetstream-2024-05-01_0.txt\",\n",
            "  \"modelOrganization\": \"Meta\",\n",
            "  \"modelName\": \"llama3-70b-8192\",\n",
            "  \"imagePrompt\": \"You are a Canadian weatherperson. Present this jet stream information to an audience. Make it sound very Canadian. It should sound as Canadian as absolutely possible.\",\n",
            "  \"imageUrl\": \"https://weather.gc.ca/data/jet_stream/tempmapwx_e.gif\",\n",
            "  \"audioModelOrganization\": \"OpenAI\",\n",
            "  \"audioModelName\": \"tts-1\",\n",
            "  \"audioVoice\": \"onyx\",\n",
            "  \"speechAudioOutputPath\": \"/content/weatherperson/weatherperson-output-2024-05-01_0.wav\",\n",
            "  \"combinedAudioOutputPath\": \"/content/voice/ai-canadian-jetstream-2024-05-01_0.mp3\"\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the metadata file\n",
        "count = 0\n",
        "\n",
        "while os.path.exists(f\"/content/metadata/ai-canadian-jetstream-metadata-{date}_{count}.json\"):\n",
        "    count += 1\n",
        "file = open(f\"/content/metadata/ai-canadian-jetstream-metadata-{date}_{count}.json\", \"w\")\n",
        "file.write(metadata_json)\n",
        "file.close()"
      ],
      "metadata": {
        "id": "zcbHWMRZedam"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}