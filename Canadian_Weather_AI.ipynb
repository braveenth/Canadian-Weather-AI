{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOuHvIS1L/OEoSCdd7fKf95",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/braveenth/Canadian-Weather-AI/blob/main/Canadian_Weather_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Canadian Weather AI\n",
        "By: Braveenth Rasanayagam\n",
        "\n",
        "Multi-modal\n",
        "- Vision\n",
        "- Text to Voice\n",
        "\n",
        "Cloud Run Jobs"
      ],
      "metadata": {
        "id": "umi3NzPEIRQ2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 774
        },
        "id": "O2Z0y6IIqPsr",
        "outputId": "a750f965-cdca-4432-fc7f-e298ceaeb015"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://weather.gc.ca/data/jet_stream/tempmapwx_e.gif\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  270k  100  270k    0     0  1057k      0 --:--:-- --:--:-- --:--:-- 1059k\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://weather.gc.ca/data/jet_stream/tempmapwx_e.gif\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "image_url = \"https://weather.gc.ca/data/jet_stream/tempmapwx_e.gif\"\n",
        "print(image_url)\n",
        "!curl -o case_image.png {image_url}\n",
        "\n",
        "from IPython.display import Image\n",
        "Image(\"/content/jet_stream.png\")\n",
        "Image(url=image_url)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "from openai import OpenAI\n",
        "\n",
        "try:\n",
        "    # Attempt to import the google.colab module to see if the program is running in Colab.\n",
        "    from google.colab import userdata\n",
        "    print(\"Running on Google Colab\")\n",
        "    !pip install openai\n",
        "    !pip install pydub\n",
        "    !pip install anthropic\n",
        "    !pip install -U -q google-generativeai\n",
        "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "    ANTHRONPIC_API_KEY = userdata.get('ANTHROPIC_API_KEY')\n",
        "    GOOGLE_API_KEY = userdata.get('AI_STUDIO_KEY')\n",
        "    !mkdir -p /content/text\n",
        "    !mkdir -p /content/voice\n",
        "    !mkdir -p /content/assets\n",
        "    !mkdir -p /content/metadata\n",
        "    !mkdir -p /content/weatherperson\n",
        "    !curl -o \"/content/assets/WeatherNetwork.mp3\" \"https://storage.googleapis.com/can-weather-ai/assets/WeatherNetwork.mp3\"\n",
        "\n",
        "except ImportError:\n",
        "    # The ImportError exception will be raised if the google.colab module is not found,\n",
        "    # indicating that the program is not running inside Google Colab.\n",
        "    print(\"Running outside of Google Colab\")\n",
        "    OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')\n",
        "    ANTHRONPIC_API_KEY = os.environ.get('ANTHROPIC_API_KEY')\n",
        "    GOOGLE_API_KEY = os.environ.get('GOOGLE_AI_STUDIO_KEY')\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DWsynJMzX29",
        "outputId": "cb525ae4-3f7d-44d0-cd5a-26aed360fd23"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on Google Colab\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.17.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
            "Requirement already satisfied: anthropic in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from anthropic) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (2.6.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from anthropic) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->anthropic) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->anthropic) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.16.3)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.0->anthropic) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.13.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (4.66.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (6.0.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (24.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.0.7)\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 64.1M  100 64.1M    0     0  82.2M      0 --:--:-- --:--:-- --:--:-- 82.3M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This will be incorporated into the prompt in the future\n",
        "\n",
        "canadianMetric = {}\n",
        "\n",
        "canadianMetric[0] = \"not Canadian\"\n",
        "canadianMetric[1] = \"somewhat Canadian\"\n",
        "canadianMetric[2] = \"slightly Canadian\"\n",
        "canadianMetric[3] = \"moderately Canadian\"\n",
        "canadianMetric[4] = \"very Canadian\"\n",
        "canadianMetric[5] = \"as Canadian as possible\"\n",
        "\n",
        "selectedCanadianMetric = canadianMetric[4]\n",
        "langauge = \"en\"\n",
        "\n",
        "# We are allowing for multiple models to be incorporated\n",
        "modelChoice = {}\n",
        "\n",
        "modelChoice[0] = \"gpt-4-vision-preview\"\n",
        "modelChoice[1] = \"claude-3-opus-20240229\"\n",
        "modelChoice[2] = \"gemini-pro-vision\"\n",
        "modelChoice[3] = \"gemini-1.5-pro-latest\"\n",
        "\n",
        "selectedModel = modelChoice[3]"
      ],
      "metadata": {
        "id": "V8VydbPVFggt"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imagePrompt = \"You are a Canadian weatherperson. Present this jet stream information to an audience. Make it sound very Canadian. It should sound as Canadian as absolutely possible.\"\n",
        "image_url = \"https://weather.gc.ca/data/jet_stream/tempmapwx_e.gif\"\n",
        "\n",
        "if selectedModel == \"gpt-4-vision-preview\":\n",
        "  gpt_mode = \"gpt-4-vision-preview\"\n",
        "  imagePrompt = \"You are a Canadian weatherperson. Present this jet stream information to an audience. Make it sound very Canadian. It should sound as Canadian as absolutely possible.\"\n",
        "  image_url = \"https://weather.gc.ca/data/jet_stream/tempmapwx_e.gif\"\n",
        "  multimodalModelOrg = \"OpenAI\"\n",
        "\n",
        "  response = client.chat.completions.create(\n",
        "    model=\"gpt-4-vision-preview\",\n",
        "    messages=[\n",
        "      {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "          {\"type\": \"text\", \"text\": imagePrompt},\n",
        "          {\n",
        "            \"type\": \"image_url\",\n",
        "            \"image_url\": {\n",
        "              \"url\": image_url,\n",
        "            },\n",
        "          },\n",
        "        ],\n",
        "      }\n",
        "    ],\n",
        "    max_tokens=600,\n",
        "    temperature=0.7,\n",
        "    top_p=1,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0\n",
        "  )\n",
        "  weatherScript = response.choices[0].message.content\n",
        "  print(response.choices[0])\n",
        "\n",
        "elif selectedModel == \"claude-3-opus-20240229\":\n",
        "  import anthropic\n",
        "  import base64\n",
        "  import httpx\n",
        "  claude_mode = \"claude-3-opus-20240229\"\n",
        "  multimodalModelOrg = \"Anthropic\"\n",
        "\n",
        "  client = anthropic.Anthropic(\n",
        "      api_key=ANTHRONPIC_API_KEY,\n",
        "  )\n",
        "\n",
        "  image_media_type = \"image/gif\"\n",
        "  image_data = base64.b64encode(httpx.get(image_url).content).decode(\"utf-8\")\n",
        "  imagePrompt += \"Do not put any statements with asterisks surrounding them. Only give the speech, and nothing else. For example, statements similar to the following should be excluded: *clears throat*\"\n",
        "\n",
        "  message = client.messages.create(\n",
        "      model=\"claude-3-opus-20240229\",\n",
        "      max_tokens=1024,\n",
        "      messages=[\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": [\n",
        "                  {\n",
        "                      \"type\": \"image\",\n",
        "                      \"source\": {\n",
        "                          \"type\": \"base64\",\n",
        "                          \"media_type\": image_media_type,\n",
        "                          \"data\": image_data,\n",
        "                      },\n",
        "                  },\n",
        "                  {\n",
        "                      \"type\": \"text\",\n",
        "                      \"text\": imagePrompt\n",
        "                  }\n",
        "              ],\n",
        "          }\n",
        "      ],\n",
        "  )\n",
        "  weatherScript = message.content[0].text\n",
        "  print(weatherScript)\n",
        "\n",
        "elif selectedModel == \"gemini-1.5-pro-latest\":\n",
        "  model = genai.GenerativeModel('models/gemini-1.5-pro-latest')\n",
        "  imagePrompt = \"You are a Canadian weatherperson. Present this jet stream information to an audience. Make it sound very Canadian. It should sound as Canadian as absolutely possible.\"\n",
        "  image_url = \"https://weather.gc.ca/data/jet_stream/tempmapwx_e.gif\"\n",
        "  multimodalModelOrg = \"Google\"\n",
        "\n",
        "  response = model.generate_content([imagePrompt, image_url])\n",
        "  weatherScript = response.text\n",
        "  print(weatherScript)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "1ChT820dxzsj",
        "outputId": "13daeea4-08f6-47f3-9bc8-7bee20a6a263"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alright folks, eh, let's take a gander at this jet stream, shall we? So, picture this: it's like a giant river of air, way up high, zipping around the globe faster than a Timbit disappears at a hockey game. \n",
            "\n",
            "Now, this here map shows us where that river is flowing, and how cold it is. The blue and purple bits, those are the chilly parts, colder than a polar bear's nose in January. That's where the jet stream is dippin' down low, bringing that brisk air from the north, like a fresh breeze off the lake, eh? \n",
            "\n",
            "So, if you're under one of those blue streaks, well, bundle up, bud! You might need a toque and a double-double to stay warm. \n",
            "\n",
            "And for those of you lucky ducks under the orange and red bits, well, you're basking in the warmth, like a sunbathing loon on a summer day.  \n",
            "\n",
            "Just remember, folks, this jet stream is always on the move, like a Canadian goose headin' south for the winter. So, keep yer eyes on the forecast, and don't get caught with your toque off! \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(weatherScript)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4no0kaGL0tAT",
        "outputId": "b3835f62-77b5-4945-9815-39ffb117175b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alright folks, eh, let's take a gander at this jet stream, shall we? So, picture this: it's like a giant river of air, way up high, zipping around the globe faster than a Timbit disappears at a hockey game. \n",
            "\n",
            "Now, this here map shows us where that river is flowing, and how cold it is. The blue and purple bits, those are the chilly parts, colder than a polar bear's nose in January. That's where the jet stream is dippin' down low, bringing that brisk air from the north, like a fresh breeze off the lake, eh? \n",
            "\n",
            "So, if you're under one of those blue streaks, well, bundle up, bud! You might need a toque and a double-double to stay warm. \n",
            "\n",
            "And for those of you lucky ducks under the orange and red bits, well, you're basking in the warmth, like a sunbathing loon on a summer day.  \n",
            "\n",
            "Just remember, folks, this jet stream is always on the move, like a Canadian goose headin' south for the winter. So, keep yer eyes on the forecast, and don't get caught with your toque off! \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the weatherScript as a file\n",
        "from datetime import datetime\n",
        "\n",
        "# Adding timezone\n",
        "import pytz\n",
        "timezone = pytz.timezone('America/Toronto')\n",
        "now_in_timezone = datetime.now(timezone)\n",
        "\n",
        "# Format the date\n",
        "date = now_in_timezone.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "#date = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "count = 0\n",
        "\n",
        "while os.path.exists(f\"/content/text/ai-canadian-jetstream-{date}_{count}.txt\"):\n",
        "    count += 1\n",
        "file = open(f\"/content/text/ai-canadian-jetstream-{date}_{count}.txt\", \"w\")\n",
        "file.write(weatherScript)\n",
        "file.close()"
      ],
      "metadata": {
        "id": "4xmiS2I3a3Sp"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "try:\n",
        "    # Attempt to import the google.colab module to see if the program is running in Colab.\n",
        "    from google.colab import userdata\n",
        "    print(\"Running on Google Colab\")\n",
        "    audioClient = OpenAI(api_key=userdata.get('OPENAI_API_KEY'))\n",
        "\n",
        "except ImportError:\n",
        "    # The ImportError exception will be raised if the google.colab module is not found,\n",
        "    # indicating that the program is not running inside Google Colab.\n",
        "    import os\n",
        "    print(\"Running outside of Google Colab\")\n",
        "    audioClient = OpenAI(api_key=(os.environ.get('OPENAI_API_KEY')))\n",
        "\n",
        "audioModelOrg = \"OpenAI\"\n",
        "audioModel = \"tts-1\"\n",
        "audioVoice = \"onyx\"\n",
        "\n",
        "audioResponse = audioClient.audio.speech.create(\n",
        "    model=audioModel,\n",
        "    voice=audioVoice,\n",
        "    input=weatherScript,\n",
        ")\n",
        "\n",
        "filename = f\"weatherperson-output-{date}.mp3\""
      ],
      "metadata": {
        "id": "3ZH_07Z71B7C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8343f10-7599-48db-e2c9-e37210dbf5c5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on Google Colab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audioResponse.stream_to_file(filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3cSZyLe2GXl",
        "outputId": "e763ce84-9b54-4883-8f1e-edf9964ae932"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-02f298be9c94>:1: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
            "  audioResponse.stream_to_file(filename)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "\n",
        "# Export the result\n",
        "weatherPersonFileCount = 0\n",
        "while os.path.exists(f\"/content/weatherperson/weatherperson-output-{date}_{weatherPersonFileCount}.wav\"):\n",
        "    weatherPersonFileCount += 1\n",
        "\n",
        "weatherpersonFile = f\"/content/weatherperson/{filename}-{count}\"\n",
        "audioResponse.stream_to_file(f\"/content/weatherperson/weatherperson-output-{date}_{weatherPersonFileCount}.wav\")\n",
        "\n",
        "# Obtain Audio Files\n",
        "audio_bg_music = AudioSegment.from_file(\"/content/assets/WeatherNetwork.mp3\", format=\"mp3\")\n",
        "audio_weatherperson = AudioSegment.from_file(f\"/content/weatherperson/weatherperson-output-{date}_{weatherPersonFileCount}.wav\", format=\"mp3\")\n",
        "\n",
        "# BG Music Segments from https://www.youtube.com/watch?v=6E2uzYAGPQU\n",
        "#####################################################################\n",
        "# 01. Morning Report (1998) Conclusions 0:00. #\n",
        "# 02. Autumn (1999) Flying V.1 1:59 #\n",
        "# 03. Holidays (2000) Xmas Spirit 3:29\n",
        "# 04. Biding My Time 4:59\n",
        "# 05. Winter (2002-'03) Life to the Full 7:12\n",
        "# 06. Spring-Autumn (2003) Healthy Outlook 8:42\n",
        "# 07. Winter (2003-04) Embrace Life 10:43\n",
        "# 08. Primary Theme (2004-05) Lazing on the Slopes 13:16\n",
        "# 09. Theme (2005-06) Windstar 15:17\n",
        "# 10. Theme (2006-10) 17:17\n",
        "# 11. Theme (2010-201?) Song Contest Winner 19:37\n",
        "# 12. Holiday Version of Theme 11 (2011) 21:58\n",
        "# 13. 25th Anniversary (2004-05 Secondary Theme) 25:02\n",
        "\n",
        "segments = [0] * 12\n",
        "segments[0] = [0, 119000, 7]\n",
        "segments[1] = [119000, 209000, 7]\n",
        "segments[2] = [209000, 299000, 7]\n",
        "segments[3] = [299000, 432000, 7]\n",
        "segments[4] = [432000, 522000, 7]\n",
        "segments[5] = [522000, 643000, 7]\n",
        "segments[6] = [643000, 796000, 7]\n",
        "segments[7] = [796000, 917000, 7]\n",
        "segments[8] = [917000, 1037000, 7]\n",
        "segments[9] = [1037000, 1177000, 7]\n",
        "segments[10] = [1177000, 1318000, 11]\n",
        "segments[11] = [1318000, 1502000, 7]\n",
        "\n",
        "# Custom timing adjustments based on listening observations\n",
        "segments[8][0] = segments[8][0] + 8000\n",
        "\n",
        "# Define start and end times in milliseconds\n",
        "# Start at 17:22\n",
        "# End at 17:3\n",
        "start_time = 1042000  # Start at 10 seconds\n",
        "end_time = start_time + 120000\n",
        "\n",
        "# Use a Random number between 0 an 11 to obtain the segment number\n",
        "import random\n",
        "segment_number = random.randint(0, 11)\n",
        "\n",
        "# Using Segments Here\n",
        "start_time = segments[segment_number][0] + 1000\n",
        "end_time = segments[segment_number][1]\n",
        "\n",
        "# Slice the audio segment to the desired part\n",
        "specific_part = audio_bg_music[start_time:end_time]\n",
        "\n",
        "# Lower the volume by 10 dB\n",
        "specific_part_quieter = specific_part - segments[segment_number][2]\n",
        "\n",
        "# TO-DO: if the audio_weatherperson audio length is longer than the specific_part_quieter, then add some padding to the end of the specific_part_quieter\n",
        "lenBackgroundMusicMS = end_time - start_time\n",
        "lenAudioWeatherPersonMS = len(audio_weatherperson)\n",
        "if lenAudioWeatherPersonMS > lenBackgroundMusicMS:\n",
        "    from pydub.generators import Silence\n",
        "    padding_length_ms = lenAudioWeatherPersonMS - lenBackgroundMusicMS + 1000\n",
        "    #padding = Silence().to_audio_segment(duration=padding_length_ms, frame_rate=44100)\n",
        "    padding = AudioSegment.silent(duration=padding_length_ms)\n",
        "    specific_part_quieter = specific_part_quieter.append(padding)\n",
        "\n",
        "# TO_DO: Add audio ducking\n",
        "\n",
        "# Overlay the audio files\n",
        "# Here, overlay_audio will start at 0 milliseconds into base_audio\n",
        "combined = specific_part_quieter.overlay(audio_weatherperson, position=0)\n",
        "\n",
        "# Export the result\n",
        "count = 0\n",
        "while os.path.exists(f\"/content/voice/ai-canadian-jetstream-{date}_{count}.mp3\"):\n",
        "    count += 1\n",
        "combined.export(f\"/content/voice/ai-canadian-jetstream-{date}_{count}.mp3\", format=\"mp3\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSjR8yY93MMI",
        "outputId": "7ad6bb6a-8ce3-4212-f449-fe0910470637"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-05985a220305>:9: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
            "  audioResponse.stream_to_file(f\"/content/weatherperson/weatherperson-output-{date}_{weatherPersonFileCount}.wav\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_io.BufferedRandom name='/content/voice/ai-canadian-jetstream-2024-04-13_1.mp3'>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TO-DO: Create JSON that can be imported into BigQuery\n",
        "# Use Colab's Variable Inspector to determine which variables shoudl be captured.\n",
        "\n",
        "metadata_json = f\"\"\"{{\n",
        "  timestamp = {date}\n",
        "  timezone = {timezone}\n",
        "  weather_script = {weatherScript}\n",
        "  weather_script_path = /content/text/ai-canadian-jetstream-{date}_{count}.txt\n",
        "  multimodal_model_organization = {multimodalModelOrg}\n",
        "  multimodal_model = {selectedModel}\n",
        "  image_prompt = {imagePrompt}\n",
        "  image_url = {image_url}\n",
        "  audio_model_organization = {audioModelOrg}\n",
        "  audio_model = {audioModel}\n",
        "  audio_voice = {audioVoice}\n",
        "  image_url = {image_url}\n",
        "  output_speech_path = /content/weatherperson/weatherperson-output-{date}_{weatherPersonFileCount}.wav\n",
        "  output_combined_path = /content/voice/ai-canadian-jetstream-{date}_{count}.mp3\n",
        "}}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "p0913eMcWFOZ"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(metadata_json)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cM5rsLaq_bch",
        "outputId": "e466b12f-c9a2-4000-9839-7635eb58a92b"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  timestamp = 2024-04-13\n",
            "  timezone = America/Toronto\n",
            "  weather_script = Alright folks, eh, let's take a gander at this jet stream, shall we? So, picture this: it's like a giant river of air, way up high, zipping around the globe faster than a Timbit disappears at a hockey game. \n",
            "\n",
            "Now, this here map shows us where that river is flowing, and how cold it is. The blue and purple bits, those are the chilly parts, colder than a polar bear's nose in January. That's where the jet stream is dippin' down low, bringing that brisk air from the north, like a fresh breeze off the lake, eh? \n",
            "\n",
            "So, if you're under one of those blue streaks, well, bundle up, bud! You might need a toque and a double-double to stay warm. \n",
            "\n",
            "And for those of you lucky ducks under the orange and red bits, well, you're basking in the warmth, like a sunbathing loon on a summer day.  \n",
            "\n",
            "Just remember, folks, this jet stream is always on the move, like a Canadian goose headin' south for the winter. So, keep yer eyes on the forecast, and don't get caught with your toque off! \n",
            "\n",
            "  weather_script_path = /content/text/ai-canadian-jetstream-2024-04-13_0.txt\n",
            "  multimodal_model_organization = Google\n",
            "  multimodal_model = gemini-1.5-pro-latest\n",
            "  image_prompt = You are a Canadian weatherperson. Present this jet stream information to an audience. Make it sound very Canadian. It should sound as Canadian as absolutely possible.\n",
            "  image_url = https://weather.gc.ca/data/jet_stream/tempmapwx_e.gif\n",
            "  audio_url = test\n",
            "  audio_model_organization = OpenAI\n",
            "  audio_model = tts-1\n",
            "  audio_voice = onyx\n",
            "  image_url = https://weather.gc.ca/data/jet_stream/tempmapwx_e.gif\n",
            "  prompt = test\n",
            "  output_speech_path = /content/weatherperson/weatherperson-output-2024-04-13_0.wav\n",
            "  output_combined_path = /content/voice/ai-canadian-jetstream-2024-04-13_0.mp3\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the metadata file\n",
        "count = 0\n",
        "\n",
        "while os.path.exists(f\"/content/metadata/ai-canadian-jetstream-metadata-{date}_{count}.json\"):\n",
        "    count += 1\n",
        "file = open(f\"/content/metadata/ai-canadian-jetstream-metadata-{date}_{count}.json\", \"w\")\n",
        "file.write(metadata_json)\n",
        "file.close()"
      ],
      "metadata": {
        "id": "zcbHWMRZedam"
      },
      "execution_count": 41,
      "outputs": []
    }
  ]
}