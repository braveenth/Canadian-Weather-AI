{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOLHOLN8A/Cdn7DIuHGfGAL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/braveenth/Canadian-Weather-AI/blob/main/Canadian_Weather_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Canadian Weather AI\n",
        "By: Braveenth Rasanayagam\n",
        "\n",
        "Multi-modal\n",
        "- Vision\n",
        "- Text to Voice\n",
        "\n",
        "Cloud Run Jobs"
      ],
      "metadata": {
        "id": "umi3NzPEIRQ2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 774
        },
        "id": "O2Z0y6IIqPsr",
        "outputId": "9d841794-f53c-4f92-a573-e872f05beba3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://weather.gc.ca/data/jet_stream/tempmapwx_e.gif\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  292k  100  292k    0     0   117k      0  0:00:02  0:00:02 --:--:--  117k\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://weather.gc.ca/data/jet_stream/tempmapwx_e.gif\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "image_url = \"https://weather.gc.ca/data/jet_stream/tempmapwx_e.gif\"\n",
        "print(image_url)\n",
        "!curl -o case_image.png {image_url}\n",
        "\n",
        "from IPython.display import Image\n",
        "Image(\"/content/jet_stream.png\")\n",
        "Image(url=image_url)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "try:\n",
        "    # Attempt to import the google.colab module to see if the program is running in Colab.\n",
        "    from google.colab import userdata\n",
        "    print(\"Running on Google Colab\")\n",
        "    !pip install openai\n",
        "    !pip install pydub\n",
        "    !pip install anthropic\n",
        "    from openai import OpenAI\n",
        "    client = OpenAI(api_key=userdata.get('OPENAI_API_KEY'))\n",
        "    ANTHRONPIC_API_KEY = userdata.get('ANTHROPIC_API_KEY')\n",
        "    !mkdir -p /content/text\n",
        "    !mkdir -p /content/voice\n",
        "    !mkdir -p /content/assets\n",
        "    !curl -o \"/content/assets/WeatherNetwork.mp3\" \"https://storage.googleapis.com/can-weather-ai/assets/WeatherNetwork.mp3\"\n",
        "\n",
        "except ImportError:\n",
        "    # The ImportError exception will be raised if the google.colab module is not found,\n",
        "    # indicating that the program is not running inside Google Colab.\n",
        "    print(\"Running outside of Google Colab\")\n",
        "    from openai import OpenAI\n",
        "    client = OpenAI(api_key=(os.environ.get('OPENAI_API_KEY')))\n",
        "    ANTHRONPIC_API_KEY = os.environ.get('ANTHROPIC_API_KEY')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DWsynJMzX29",
        "outputId": "c6f3886c-3486-4624-a34c-1972badc0ec5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on Google Colab\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.16.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
            "Requirement already satisfied: anthropic in /usr/local/lib/python3.10/dist-packages (0.21.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from anthropic) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (2.6.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from anthropic) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->anthropic) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->anthropic) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.16.3)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.0->anthropic) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.13.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (4.66.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (6.0.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (24.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.0.7)\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 64.1M  100 64.1M    0     0  15.4M      0  0:00:04  0:00:04 --:--:-- 15.4M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This will be incorporated into the prompt in the future\n",
        "\n",
        "canadianMetric = {}\n",
        "\n",
        "canadianMetric[0] = \"not Canadian\"\n",
        "canadianMetric[1] = \"somewhat Canadian\"\n",
        "canadianMetric[2] = \"slightly Canadian\"\n",
        "canadianMetric[3] = \"moderately Canadian\"\n",
        "canadianMetric[4] = \"very Canadian\"\n",
        "canadianMetric[5] = \"as Canadian as possible\"\n",
        "\n",
        "selectedCanadianMetric = canadianMetric[4]\n",
        "langauge = \"en\"\n",
        "\n",
        "# We are allowing for multiple models to be incorporated\n",
        "modelChoice = {}\n",
        "\n",
        "modelChoice[0] = \"gpt-4-vision-preview\"\n",
        "modelChoice[1] = \"claude-3-opus-20240229\"\n",
        "\n",
        "selectedModel = modelChoice[1]"
      ],
      "metadata": {
        "id": "V8VydbPVFggt"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imagePrompt = \"You are a Canadian weatherperson. Present this jet stream information to an audience. Make it sound very Canadian. It should sound as Canadian as absolutely possible.\"\n",
        "image_url = \"https://weather.gc.ca/data/jet_stream/tempmapwx_e.gif\"\n",
        "\n",
        "if selectedModel == \"gpt-4-vision-preview\":\n",
        "  gpt_mode = \"gpt-4-vision-preview\"\n",
        "  imagePrompt = \"You are a Canadian weatherperson. Present this jet stream information to an audience. Make it sound very Canadian. It should sound as Canadian as absolutely possible.\"\n",
        "  image_url = \"https://weather.gc.ca/data/jet_stream/tempmapwx_e.gif\"\n",
        "\n",
        "  response = client.chat.completions.create(\n",
        "    model=\"gpt-4-vision-preview\",\n",
        "    messages=[\n",
        "      {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "          {\"type\": \"text\", \"text\": imagePrompt},\n",
        "          {\n",
        "            \"type\": \"image_url\",\n",
        "            \"image_url\": {\n",
        "              \"url\": image_url,\n",
        "            },\n",
        "          },\n",
        "        ],\n",
        "      }\n",
        "    ],\n",
        "    max_tokens=600,\n",
        "    temperature=0.7,\n",
        "    top_p=1,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0\n",
        "  )\n",
        "  weatherScript = response.choices[0].message.content\n",
        "  print(response.choices[0])\n",
        "\n",
        "elif selectedModel == \"claude-3-opus-20240229\":\n",
        "  import anthropic\n",
        "  import base64\n",
        "  import httpx\n",
        "  claude_mode = \"claude-3-opus-20240229\"\n",
        "\n",
        "  client = anthropic.Anthropic(\n",
        "      api_key=ANTHRONPIC_API_KEY,\n",
        "  )\n",
        "\n",
        "  image_media_type = \"image/gif\"\n",
        "  image_data = base64.b64encode(httpx.get(image_url).content).decode(\"utf-8\")\n",
        "  imagePrompt += \"Do not put any statements with asterisks surrounding them. Only give the speech, and nothing else. For example, statements similar to the following should be excluded: *clears throat*\"\n",
        "\n",
        "  message = client.messages.create(\n",
        "      model=\"claude-3-opus-20240229\",\n",
        "      max_tokens=1024,\n",
        "      messages=[\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": [\n",
        "                  {\n",
        "                      \"type\": \"image\",\n",
        "                      \"source\": {\n",
        "                          \"type\": \"base64\",\n",
        "                          \"media_type\": image_media_type,\n",
        "                          \"data\": image_data,\n",
        "                      },\n",
        "                  },\n",
        "                  {\n",
        "                      \"type\": \"text\",\n",
        "                      \"text\": imagePrompt\n",
        "                  }\n",
        "              ],\n",
        "          }\n",
        "      ],\n",
        "  )\n",
        "  weatherScript = message.content[0].text\n",
        "  print(weatherScript)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ChT820dxzsj",
        "outputId": "77f2f875-3e65-467c-d5ac-2d2df7ea7d9b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ooo boy, would ya take a gander at this jet stream map, eh? We've got quite the situaaaation brewin' over the Great White North today!\n",
            "\n",
            "Looks like a big ol' trough is dippin' down over BC and Alberta, bringin' some chilly arctic air. Meanwhile, a real beaut of a ridge is buildin' over Quebec and the Maritimes. That's gonna serve up some milder temps for the folks out east, dontcha know.\n",
            "\n",
            "But hold onto yer toques! Smack dab in the middle, from Manitoba to Ontario, the jet stream's takin' a wild ride. It's zippin' and zappin' all over the place like a hockey player danglin' through traffic. That's a recipe for some unsettled weather with a chance of Timbits precipitation, I tell ya!\n",
            "\n",
            "So there ya have it, my fellow Canucks. Keep your stick on the ice and your eyes on the skies. And remember, whether you're weatherin' a Prairie blizzard or soakin' up a wee bit of East Coast sun, we're all in this together. Stay warm out there and don't forget to top up yer double-double!\n",
            "\n",
            "This has been yer trusty Canadian weather hoser, over and oot!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(weatherScript)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4no0kaGL0tAT",
        "outputId": "617eca7d-94d8-4b61-8755-8f6a4fc10ea1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ooo boy, would ya take a gander at this jet stream map, eh? We've got quite the situaaaation brewin' over the Great White North today!\n",
            "\n",
            "Looks like a big ol' trough is dippin' down over BC and Alberta, bringin' some chilly arctic air. Meanwhile, a real beaut of a ridge is buildin' over Quebec and the Maritimes. That's gonna serve up some milder temps for the folks out east, dontcha know.\n",
            "\n",
            "But hold onto yer toques! Smack dab in the middle, from Manitoba to Ontario, the jet stream's takin' a wild ride. It's zippin' and zappin' all over the place like a hockey player danglin' through traffic. That's a recipe for some unsettled weather with a chance of Timbits precipitation, I tell ya!\n",
            "\n",
            "So there ya have it, my fellow Canucks. Keep your stick on the ice and your eyes on the skies. And remember, whether you're weatherin' a Prairie blizzard or soakin' up a wee bit of East Coast sun, we're all in this together. Stay warm out there and don't forget to top up yer double-double!\n",
            "\n",
            "This has been yer trusty Canadian weather hoser, over and oot!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the weatherScript as a file\n",
        "from datetime import datetime\n",
        "\n",
        "# Adding timezone\n",
        "import pytz\n",
        "timezone = pytz.timezone('America/Toronto')\n",
        "now_in_timezone = datetime.now(timezone)\n",
        "\n",
        "# Format the date\n",
        "date = now_in_timezone.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "#date = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "count = 0\n",
        "\n",
        "while os.path.exists(f\"/content/text/ai-canadian-jetstream-{date}_{count}.txt\"):\n",
        "    count += 1\n",
        "file = open(f\"/content/text/ai-canadian-jetstream-{date}_{count}.txt\", \"w\")\n",
        "file.write(weatherScript)\n",
        "file.close()"
      ],
      "metadata": {
        "id": "4xmiS2I3a3Sp"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "try:\n",
        "    # Attempt to import the google.colab module to see if the program is running in Colab.\n",
        "    from google.colab import userdata\n",
        "    print(\"Running on Google Colab\")\n",
        "    audioClient = OpenAI(api_key=userdata.get('OPENAI_API_KEY'))\n",
        "\n",
        "except ImportError:\n",
        "    # The ImportError exception will be raised if the google.colab module is not found,\n",
        "    # indicating that the program is not running inside Google Colab.\n",
        "    import os\n",
        "    print(\"Running outside of Google Colab\")\n",
        "    audioClient = OpenAI(api_key=(os.environ.get('OPENAI_API_KEY')))\n",
        "\n",
        "audioResponse = audioClient.audio.speech.create(\n",
        "    model=\"tts-1\",\n",
        "    voice=\"onyx\",\n",
        "    input=weatherScript,\n",
        ")\n",
        "\n",
        "filename = f\"weatherperson-output-{date}.mp3\""
      ],
      "metadata": {
        "id": "3ZH_07Z71B7C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be955c6e-648d-4bab-83ca-5ef54f2ca1c5"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on Google Colab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audioResponse.stream_to_file(filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3cSZyLe2GXl",
        "outputId": "db59a8b5-78c7-4856-a4c9-00cd61b82c0a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-02f298be9c94>:1: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
            "  audioResponse.stream_to_file(filename)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "\n",
        "# Export the result\n",
        "weatherPersonFileCount = 0\n",
        "while os.path.exists(f\"/content/weatherperson-output-{date}_{weatherPersonFileCount}.wav\"):\n",
        "    weatherPersonFileCount += 1\n",
        "\n",
        "weatherpersonFile = f\"/content/{filename}-{count}\"\n",
        "audioResponse.stream_to_file(f\"/content/weatherperson-output-{date}_{weatherPersonFileCount}.wav\")\n",
        "\n",
        "# Obtain Audio Files\n",
        "audio_bg_music = AudioSegment.from_file(\"/content/assets/WeatherNetwork.mp3\", format=\"mp3\")\n",
        "audio_weatherperson = AudioSegment.from_file(f\"/content/weatherperson-output-{date}_{weatherPersonFileCount}.wav\", format=\"mp3\")\n",
        "\n",
        "# BG Music Segments from https://www.youtube.com/watch?v=6E2uzYAGPQU\n",
        "#####################################################################\n",
        "# 01. Morning Report (1998) Conclusions 0:00. #\n",
        "# 02. Autumn (1999) Flying V.1 1:59 #\n",
        "# 03. Holidays (2000) Xmas Spirit 3:29\n",
        "# 04. Biding My Time 4:59\n",
        "# 05. Winter (2002-'03) Life to the Full 7:12\n",
        "# 06. Spring-Autumn (2003) Healthy Outlook 8:42\n",
        "# 07. Winter (2003-04) Embrace Life 10:43\n",
        "# 08. Primary Theme (2004-05) Lazing on the Slopes 13:16\n",
        "# 09. Theme (2005-06) Windstar 15:17\n",
        "# 10. Theme (2006-10) 17:17\n",
        "# 11. Theme (2010-201?) Song Contest Winner 19:37\n",
        "# 12. Holiday Version of Theme 11 (2011) 21:58\n",
        "# 13. 25th Anniversary (2004-05 Secondary Theme) 25:02\n",
        "\n",
        "segments = [0] * 12\n",
        "segments[0] = [0, 119000, 7]\n",
        "segments[1] = [119000, 209000, 7]\n",
        "segments[2] = [209000, 299000, 7]\n",
        "segments[3] = [299000, 432000, 7]\n",
        "segments[4] = [432000, 522000, 7]\n",
        "segments[5] = [522000, 643000, 7]\n",
        "segments[6] = [643000, 796000, 7]\n",
        "segments[7] = [796000, 917000, 7]\n",
        "segments[8] = [917000, 1037000, 7]\n",
        "segments[9] = [1037000, 1177000, 7]\n",
        "segments[10] = [1177000, 1318000, 11]\n",
        "segments[11] = [1318000, 1502000, 7]\n",
        "\n",
        "# Custom timing adjustments based on listening observations\n",
        "segments[8][0] = segments[8][0] + 8000\n",
        "\n",
        "# Define start and end times in milliseconds\n",
        "# Start at 17:22\n",
        "# End at 17:3\n",
        "start_time = 1042000  # Start at 10 seconds\n",
        "end_time = start_time + 120000\n",
        "\n",
        "# Use a Random number between 0 an 11 to obtain the segment number\n",
        "import random\n",
        "segment_number = random.randint(0, 11)\n",
        "\n",
        "# Using Segments Here\n",
        "start_time = segments[segment_number][0] + 1000\n",
        "end_time = segments[segment_number][1]\n",
        "\n",
        "# Slice the audio segment to the desired part\n",
        "specific_part = audio_bg_music[start_time:end_time]\n",
        "\n",
        "# Lower the volume by 10 dB\n",
        "specific_part_quieter = specific_part - segments[segment_number][2]\n",
        "\n",
        "# TO-DO: if the audio_weatherperson audio length is longer than the specific_part_quieter, then add some padding to the end of the specific_part_quieter\n",
        "lenBackgroundMusicMS = end_time - start_time\n",
        "lenAudioWeatherPersonMS = len(audio_weatherperson)\n",
        "if lenAudioWeatherPersonMS > lenBackgroundMusicMS:\n",
        "    from pydub.generators import Silence\n",
        "    padding_length_ms = lenAudioWeatherPersonMS - lenBackgroundMusicMS + 1000\n",
        "    #padding = Silence().to_audio_segment(duration=padding_length_ms, frame_rate=44100)\n",
        "    padding = AudioSegment.silent(duration=padding_length_ms)\n",
        "    specific_part_quieter = specific_part_quieter.append(padding)\n",
        "\n",
        "# TO_DO: Add audio ducking\n",
        "\n",
        "# Overlay the audio files\n",
        "# Here, overlay_audio will start at 0 milliseconds into base_audio\n",
        "combined = specific_part_quieter.overlay(audio_weatherperson, position=0)\n",
        "\n",
        "# Export the result\n",
        "count = 0\n",
        "while os.path.exists(f\"/content/voice/ai-canadian-jetstream-{date}_{count}.mp3\"):\n",
        "    count += 1\n",
        "combined.export(f\"/content/voice/ai-canadian-jetstream-{date}_{count}.mp3\", format=\"mp3\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSjR8yY93MMI",
        "outputId": "2e18fde1-184a-4573-b14c-21e4cd23ed82"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-4ba39fd69ab6>:9: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
            "  audioResponse.stream_to_file(f\"/content/weatherperson-output-{date}_{weatherPersonFileCount}.wav\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_io.BufferedRandom name='/content/voice/ai-canadian-jetstream-2024-04-02_0.mp3'>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ]
}